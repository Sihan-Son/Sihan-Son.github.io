<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on Sihan`s Blog</title>
    <link>https://sihan-son.github.io/tags/ml/</link>
    <description>Recent content in ML on Sihan`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-kr</language>
    <lastBuildDate>Mon, 31 Oct 2022 22:03:08 +0900</lastBuildDate><atom:link href="https://sihan-son.github.io/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Must Have 텐초의 파이토치 딥러닝 특강</title>
      <link>https://sihan-son.github.io/book/pytorch_rabbit/</link>
      <pubDate>Mon, 31 Oct 2022 22:03:08 +0900</pubDate>
      
      <guid>https://sihan-son.github.io/book/pytorch_rabbit/</guid>
      <description>골든래빗 출판사로부터 책을 제공받아 작성했습니다
책 바로가기
알파고가 가지고 온 인고지능 쇼크 이후 벌써 6년이라는 시간이 지났습니다. 그 기간동안 다양한 인공지능/딥러닝 관련 서적들이 나왔고, tenosrflow와 pytorch가 인공지능 프레임워크의 두 기둥으로 자리 잡았습니다. 다양한 프레임워크와 네트워크/모델들이 나왔고 그래서 상대적으로 초창기에 나온 책들은 기초적인 MLP, CNN, RNN 정도를 다루고 부록에 GAN, Transformer 등 나름 트랜디하게 뒤에 나온 모델들을 소개하는 정도였습니다. 이번 책은 퍼셉트론을 시작으로 GPT, ViT등 요즘 핫하다고 할 수 있는 대규모 모델 등까지 다루고 있습니다.</description>
    </item>
    
    <item>
      <title>데싸노트의 실전에서 통하는 머신러닝, 머신러닝의 Cheat Sheet </title>
      <link>https://sihan-son.github.io/book/data_science_note_ml/</link>
      <pubDate>Wed, 07 Sep 2022 23:14:54 +0900</pubDate>
      
      <guid>https://sihan-son.github.io/book/data_science_note_ml/</guid>
      <description>골든래빗 출판사로부터 책을 제공받아 작성했습니다
책 바로가기
데싸노트의 실전에서 통하는 머신러닝을 선택하기 전에 반드시 아셔야 할 내용이 하나 있습니다. 머신러닝과 딥러닝은 다른 것입니다. 입문 단계에서 가장 많이 헷갈리고 혼용하는 것이 용어입니다. 동일 카테고리에서 특히 많은 혼동이 있는 듯 합니다. 이제는 조금 옛날 이야기가 되어버렸지만 새롭게 인공지능의 붐을 일으킨 알파고 이후 인공지능 == 머신러닝 == 딥러닝으로 알고 있는 사람이 많아져 더욱 용어에 혼란을 느끼는 사람이 많은 듯 합니다. 그래서 이 책은 제목 그대로 머신러닝만을 다루고 있습니다.</description>
    </item>
    
    <item>
      <title>연구자, 실무자 모두를 위한 머신러닝 도서 -머신러닝 파워드 애플리케이션 -</title>
      <link>https://sihan-son.github.io/book/ml_app/</link>
      <pubDate>Sat, 26 Mar 2022 22:50:56 +0900</pubDate>
      
      <guid>https://sihan-son.github.io/book/ml_app/</guid>
      <description>작년에 출간 소식을 접했을 땐 막연히 박해선 역자님의 신간이 출시 되었네 한 번 읽어봐야겠다라고 생각했던 책이었습니다. 출간 이벤트 때 책과 연이 닿지 않았고, 당장 필요한 책은 아니어서 찜 목록에 잠들어 있었습니다. 3월 리뷰 도서 리스트에서 다시 만났을 때도 제목만 보고 뭐 서빙 도구들을 연결하고, 연구와는 다른 접근법이 필요하다 정도의 상투적인 내용이지 않을까 지레짐작하며 희망 도서 3권 중 한 권으로 선택했습니다. 택배 파업으로 다소 늦게 선정 된 도서를 받았고, 책을 머릿말과 베타리더들의 추천사를 읽으면서 내가 짧은 식견으로 책을 섣불리 판단하고 만나지 못 할 뻔 한것을 깨달았습니다.</description>
    </item>
    
    <item>
      <title>[Book]살아 움직이는 머신러닝 파이프라인 설계</title>
      <link>https://sihan-son.github.io/book/bulding-ml-pipline/</link>
      <pubDate>Sun, 21 Nov 2021 16:13:03 +0900</pubDate>
      
      <guid>https://sihan-son.github.io/book/bulding-ml-pipline/</guid>
      <description>머신러닝을 이용한 서비스는 지속적으로 늘어나고 있는 추세입니다. ML 서비스들은 항상 최고의 수준을 유지할 것라는 기댈를 갖게 합니다. 어제보다, 지난 달 보다 더 나은 추천을 해주고, 내가 원하는 목적지를 나보다 빨리 제안하고, 음악을 큐레이션 해주는 등 사용자 경험이 나아지길 기대하며 ML 베이스 서비스를 이용하고, 기업들에서도 제공하고 있습니다.
하지만 서비스의 성능을 지속적으로 발전시키기 위해서는 자동화되고 잘 짜여진 파이프라인이 필요합니다. 이런 파이프라인 없이 엔지니어가 데이터 셋 업데이트부터 모델 서빙까지 다 맡아서 하다보면 인원의 공백이나 교체 등에 의해 퀄리티가 널 뛰게 됩니다.</description>
    </item>
    
    <item>
      <title>혼자 공부하는 머신러닝&#43;딥러닝 </title>
      <link>https://sihan-son.github.io/book/alone-dl/</link>
      <pubDate>Tue, 19 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sihan-son.github.io/book/alone-dl/</guid>
      <description>오늘은 지난번 글에서 곧 돌아오겠다고 예고한 혼자 공부하는 머신러닝+딥러닝입니다. 한빛에서 칼을 갈고 만들고 있다고 느끼는 시리즈인 혼공 시리즈의 머신러닝, 딥러닝입니다. 제일 놀란 점은 두께와 퀄리티 대비 책이 저렴하다는 점이었습니다. 600페이지에 달하는 책을 정가 26,000원이라는 생각보다 저렴한 가격에 만날 수 있습니다. 다른 인공지능 도서들이 가격이 큰 문턱이라는 걸 생각하면 이름처럼 혼자 공부하기에 부담을 덜 수 있는 책이라고 생각합니다
다른 인공지능 분야 도서들이랑 가장 큰 차별 점을 꽂으라면 첫 데이터 셋으로 MNIST, 와닿지도 않는 보스턴 집값 데이터가 아니라 혼공맨이 정말 실제로 겪을만한 데이터를 다룹니다.</description>
    </item>
    
    <item>
      <title>밑바닥부터 시작하는 딥러닝 3 </title>
      <link>https://sihan-son.github.io/book/deep-learning-from-scratch-3/</link>
      <pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://sihan-son.github.io/book/deep-learning-from-scratch-3/</guid>
      <description>Deep Learning(이하 DL)은 배우기 쉬운데 어려운, 굉장히 아이러니한 분야가 되어가고 있습니다. 강력하고 좋은 프레임워크와 튜토리얼들이 배움과 사용의 문턱을 굉장히 낮추어 주었습니다. 이는 동전의 양면처럼 장단점이 극명하게 나뉘는 결과를 초래했습니다. 문턱이 낮아지면서 다양한 아이디어와 기술들이 분야에 기여하고, 흥미 있고 능력있는 친두들을 일찍 발굴해 내는 등의 장점이 있습니다. 동시에 레토르트 식품을 서빙하는 식당들이 많아지고 있습니다. 모델에 대한 이해 없이 하이퍼파라메타와 데이터셋만 조금 바꾸어 결과를 뽑아 사용하는 말 그대로 밑바닥이 부족한 사용자들도 속출하는 듯 합니다.</description>
    </item>
    
    <item>
      <title>GANs in Action</title>
      <link>https://sihan-son.github.io/book/gans-in-action/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://sihan-son.github.io/book/gans-in-action/</guid>
      <description>정말 오랜만에 리뷰하는 인공지능 관련도서입니다! 이 책은 인공지능에서 가장 도전적인 분야 중 하나인 생성모델 중에서 적대적 생성모델(Generative Adversarial Nets 이하 GAN)을 전반적으로 다루고 있습니다. 큰 파장을 불러온 바닐라 GAN을 시작으로 GAN분야에서도 새 지평을 열어준 CGAN, CycleGAN까지 다루면서 GAN의 국한해서는 생성모델의 주요한 발전사를 옅볼수 있는 책입니다. 생성모델에 GAN 위주의 이야기가 나오지만 GAN이외에도 다야한 모델들이 있다는 것은 알아 두시면 좋을 것 같습니다.
인공지능 분야에서도 직관적이지도 않고 수학적 난이도도 있는 분야이다 보니 일정 수준에 오른 독자들이 읽기를 권하고 있습니다.</description>
    </item>
    
    <item>
      <title>Cheetah 딥러닝용 GPU 플랫폼</title>
      <link>https://sihan-son.github.io/review/cheetah-gpu/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sihan-son.github.io/review/cheetah-gpu/</guid>
      <description>Deep Learning을 공부하거나 프로젝트를 진행하려면 GPU는 필수적입니다. 저의 경우는 GTX 970모델을 이용 중이었지만 학습으로 갈궈지고, 오버워치를 하다가 퍽 하고 전원이 나가더니 죽어버리는 불상사를 겪었습니다.
졸업 프로젝트로 Deep Learning관련 프로젝트를 진행하고 있어서 GPU가 절대적으로 필요한 상황이었는데 그나마 있던 GPU가 죽어서 정말 곤란한 상황이 되었습니다. 그러던 중 머신러닝 플랫폼 서비스를 오픈해서 베타 서비스를 진행중인 Cheetah라는 플랫폼을 알게 되었습니다. 마침 베타 테스터들에게 한달간 무료로 GPU 서버를 대여 해주고 있어서 RTX 2080TI 서버를 대여해 사용할 수 있었습니다.</description>
    </item>
    
    <item>
      <title>간단하게 정리한 Mode Collapse</title>
      <link>https://sihan-son.github.io/mldl/mode-collapse/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sihan-son.github.io/mldl/mode-collapse/</guid>
      <description>저는 언제나 처럼 간단하게 이게 어떤 개념인지만 짚고 넘어가겠습니다. 자세한 내용은 다른 학술 블로그들을 참조해 주세요!
GAN관련 논문이나 자료들을 읽다 보면은 심심치 않게 mode collapse라는 말을 발견 할 수 있습니다. 여기서 mode는 수학에서 말하는 최빈값입니다. 즉 제일 자주 등장하는 값들을 말합니다. mode collapse는 보통 Multi-Modal일 경우 두드러지게 발생 할 수 있습니다. 튜토리얼로 자주 사용하는 MNIST의 경우 &amp;lsquo;0~9&amp;rsquo; 10개의 mode를 갖게 됩니다.
Generator G가 input z를 하나의 mode에 치우쳐 변화시키는 현상이 발생합니다.</description>
    </item>
    
    <item>
      <title>간단하게 정리한 Norm</title>
      <link>https://sihan-son.github.io/mldl/what-is-norm/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sihan-son.github.io/mldl/what-is-norm/</guid>
      <description>저는 언제나 처럼 간단하게 이게 어떤 개념인지만 짚고 넘어가겠습니다. 자세한 내용은 다른 학술 블로그들을 참조해 주세요! 그럼 이번 글에서는 Norm에 대한 개념을 간단하게 잡아 봅시다!
What is Norm? Norm은 수학적으로 벡터 공간 또는 행렬에 있는 모든 벡터의 전체 크기, 길이를 의미합니다. 단순화를 위해 표준이 높을수록 행렬 또는 벡터의 값이 커집니다.
p: Norm의 차수(p의 차수에 따라 L0, L1, L2 결정)
N: 대상 벡터의 요소 수
L0 Norm 실제로 Norm은 아닙니다. 벡터의 0이 아닌 요소의 총 개수를 의미합니다.</description>
    </item>
    
    <item>
      <title>머신러닝 교과서 with 파이썬, 사이킷런, 텐서플로</title>
      <link>https://sihan-son.github.io/book/ml-book-review-gilbut-1/</link>
      <pubDate>Sat, 06 Jul 2019 23:04:49 +0900</pubDate>
      
      <guid>https://sihan-son.github.io/book/ml-book-review-gilbut-1/</guid>
      <description>이 책은 다른 머신러닝 도서가 그렇듯이 인공지능이 어떤 역사를 가지고 발전했는지로 이야기를 시작합니다. 머신러닝에서 사용되는 전반인 용어와 표기법에 대한 정의로 글을 시작하기 때문에 입문서로 큰 장점이라고 생각됩니다. 입문서라고 나온 도서들 중에도 번역된 용어와 원어가 혼재되어 사용되어 인터넷에서 얻는 자료와 용어차이에서 오는 괴리감이 있는데 이 책은 그 부분을 해결 해주는 부분이 있습니다.
파이썬에 익숙하지 않은 사용자를 위해서 패키지 관리를 위해 pip와 conda에 대한 사용법도 제시하고 있습니다. 하지만 파이썬 문법에 대한 설명이 없기 때문에 파이썬은 어느 정도 익힌 다음에 읽는 것을 추천합니다.</description>
    </item>
    
    <item>
      <title>Symbolic Music Genre Transfer with CycleGAN(3)</title>
      <link>https://sihan-son.github.io/paper/3-cyclegan-music-model/</link>
      <pubDate>Fri, 05 Jul 2019 00:49:14 +0900</pubDate>
      
      <guid>https://sihan-son.github.io/paper/3-cyclegan-music-model/</guid>
      <description>Index  Intro Related Work Model Architecture Dataset and Preprocessing Architecture Parmeters and Training Experimental Results Conclusion  이 논문에서 사용하는 모델은 Generative adversarial network(GAN)에 기반을 두고 있습니다. Ian Goodfellow et al1에서 제안 된 기존의 모델에서는 Generator G와 Discriminator D가 존재 합니다. G는 노이즈를 실제 데이터 처럼 만드는 역할을 합니다. D는 G가 만들어낸 가짜 데이터와 실제 데이터를 구별하는 역할을 합니다.
Music domain transfer이기 때문에 input데이터는 노이즈가 아니라 실제 음악 데이터이고, 본 논문에서는 음악 데이터중에서 MIDI 데이터를 사용합니다.</description>
    </item>
    
    <item>
      <title>쉽게 따라하는 Tensorflow-gpu Setting with anaconda</title>
      <link>https://sihan-son.github.io/setting/tensoflow-gpu-setting/</link>
      <pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sihan-son.github.io/setting/tensoflow-gpu-setting/</guid>
      <description>Tensorflow를 사용하면서 제일 힘든 작업은 GPU를 이용한 환경을 세팅하는 일이다. CUDA, cuDNN등 여러 패키지를 설치해야하고, 또 따라하라는데로 따라하는데 블로그 글들이 업데이트가 되어 있지 않아서 버전 오류가 발생하기도 한다. 그래서 간단한 방법을 소개하려고 한다.
먼저 anaconda가 필요하다. anaconda는 과학용 파이썬 패키지를 묶어서 배포하는 배포판 인데 이 내용은 다음에 알아보도록 하고, anaconda가 설치 되어 있다는 사람들을 대상으로 글을 쓴다. 혹시 anaconda 설치가 필요하다면 이 글을 참조해서 설치하길 바란다.
먼저 python 버전이 tensorflow와 호환되는 버전이지 확인이 필요하다.</description>
    </item>
    
    <item>
      <title>Symbolic Music Genre Transfer with CycleGAN(4)</title>
      <link>https://sihan-son.github.io/paper/4-cyclegan-music-pre/</link>
      <pubDate>Thu, 04 Jul 2019 00:49:14 +0900</pubDate>
      
      <guid>https://sihan-son.github.io/paper/4-cyclegan-music-pre/</guid>
      <description>Index  Intro Related Work Model Architecture Dataset and Preprocessing Architecture Parmeters and Training Experimental Results Conclusion  Model Architecture파트전에 Dataset and Preprocessing 파트를 먼저 다루려고합니다. 이 파트는 MIDI대한 간단한 설명과 데이터 전처리 방법과 전략이 나와있는 장입니다. 미디를 다루는 딥러닝 프로젝트에 꽤 큰 도움이 될 듯 합니다.
MIDI (Musical Instrument Digital Interface)는 통신 규격을 담은 심볼릭 데이터입니다. 여기에 대한 자세한 설명은 Symbolic Music MIDI를 참조 해주세요. MIDI는 통신 규격이기 때문에 진짜 소리를 가지고 있지 않습니다.</description>
    </item>
    
    <item>
      <title>간단하게 알아보는 Difference between VAE and GAN</title>
      <link>https://sihan-son.github.io/mldl/difference-between-vae-and-gan/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sihan-son.github.io/mldl/difference-between-vae-and-gan/</guid>
      <description>What is difference between VAE and GAN VAE와 GAN은 그림에서 보다시피 Maximum Likehood의 범주에 속하는 방법론이다. 그림에서 볼 수 있든 Explicit한 방법론과 Implicit한 방법론으로 나뉜다. 이 블로그에서 주로 다루는 GAN은 보다시피 Implicit(암시적인)한 방법론을 취하고 있다.
VAE Variational Autoencoder(AVE)는 Kingma et al1의 논문에서 제안된 네트워크의 구조이다. 복잡한 데이터 생성 모델을 설계하고 대규모 데이터 세트에 적용을 할 수 있게 해준다. input을 z로 encoding하고 스스로 input을 decoding하는 방법을 학습하는 방법이다. 즉 decoding된 output이 input과 최대한 가깝게 만들어는 내는 방법이다.</description>
    </item>
    
    <item>
      <title>Simple Latent Space</title>
      <link>https://sihan-son.github.io/mldl/latent-space/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sihan-son.github.io/mldl/latent-space/</guid>
      <description>오늘은 Generative adversarial network GAN 논문을 읽거나 자료를 접하다보면 자주 보는 latent space에 대한 자료를 포스팅 하려고 합니다. 이 포스트는 아마도 지속적으로 업데이트가 진행되면서 내용이 풍부해지길 저도 기대하고 있습니다. 이 포스팅은 latent space에 대해서 간단하게 알아보는 포스팅이니 개념만 잡고 가세요. 혹시 잘못된 내용이 있다면 메일이나 댓글로 피드백 주시면 수정하도록 하겠습니다!
머신러닝의 성능은 데이터의 양과 질에 굉장히 의존적입니다. Trash in Trash out 말이 있듯이 데이터의 질에 성능이 심히 요동치게 됩니다.
그래서 데이터가 모이면 어떤 feature가 유용한지 아닌지 확인하는 작업이 필요로 합니다.</description>
    </item>
    
    <item>
      <title>Symbolic Music Genre Transfer with CycleGAN(2)</title>
      <link>https://sihan-son.github.io/paper/2-cyclegan-music-related/</link>
      <pubDate>Mon, 01 Jul 2019 00:49:14 +0900</pubDate>
      
      <guid>https://sihan-son.github.io/paper/2-cyclegan-music-related/</guid>
      <description>지난 글에 이어서 이번 글에서는 Related Work 파트의 내용을 정리해려고 합니다. 이번 파트는 선행 연국에 대한 이야기이기 때문에 레펀러스가 많이 달리고 논문 링크는 하단에 레퍼런스로 있습니다
Index  Intro Related Work Model Architecture Dataset and Preprocessing Architecture Parmeters and Training Experimental Results Conclusion  Related Work Gatys et al.1의 논문에서 Neural Style Transfer의 컨셉을 설명한다. 이 논문에서는 Pre-Trained CNN ResNet을 이용해 두 이미지의 스타일과 컨텐츠를 합친다.
CycleGAN2같은 접근에서는 explict 스타일 특성 추출이 요구되지 않는다.</description>
    </item>
    
    <item>
      <title>Symbolic Music Genre Transfer with CycleGAN(1)</title>
      <link>https://sihan-son.github.io/paper/1-cyclegan-music-intro/</link>
      <pubDate>Sat, 29 Jun 2019 00:49:14 +0900</pubDate>
      
      <guid>https://sihan-son.github.io/paper/1-cyclegan-music-intro/</guid>
      <description>졸업 작품으로 Generative adversarial network(GAN)을 이용해 작곡을 하려고 했다. 프로젝트 진행을 위해 자료 수집을 진행하며 지도 교수님과 이야기를 통해 작곡에서 domain transfer 즉 음악의 편곡으로 방향을 선회해 프로젝트를 진행하게 되었다. 핵심적으로 본 논문들을 리뷰하면서 공부한 내용을 정리하고자 한다. 수학적 베이스가 약해서 논문을 읽으면서 가장 힘들었던 부분이 Loss function에 관한 내용이었던 만큼 이 부분의 감안하고 읽어 주세요. 논문 리뷰 이후에 github에 공개된 코드를 리뷰해 보려고 합니다
처음으로 살펴볼 논문은 Symbolic Music Genre Transfer with CycleGAN입니다.</description>
    </item>
    
  </channel>
</rss>
